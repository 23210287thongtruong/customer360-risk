env {
  execution.parallelism = 4
  job.mode = "BATCH"
  spark.master = "spark://spark-master:7077"
}

source {
  LocalFile {
    path = "/opt/data/raw/transactions.csv"
    file_format_type = "csv"
    schema = {
      fields {
        transaction_id = string
        customer_id = string
        transaction_type = string
        amount = double
        timestamp = string
        merchant_name = string
        merchant_category = string
        location_city = string
        location_state = string
        is_weekend = boolean
        hour = int
        is_online = boolean
        is_fraud = boolean
      }
    }
    result_table_name = "transactions_raw"
  }
}

transform {
  Sql {
    sql = "
      SELECT 
        transaction_id,
        customer_id,
        transaction_type,
        CAST(amount AS DECIMAL(12,2)) as amount,
        CAST(timestamp AS TIMESTAMP) as timestamp,
        merchant_name,
        merchant_category,
        location_city,
        location_state,
        is_weekend,
        hour,
        is_online,
        is_fraud,
        CURRENT_TIMESTAMP as ingestion_timestamp
      FROM transactions_raw
      WHERE transaction_id IS NOT NULL
        AND customer_id IS NOT NULL
        AND amount > 0
    "
    result_table_name = "transactions_clean"
  }
}

sink {
  Jdbc {
    url = "jdbc:postgresql://postgres:5432/customer360_dw"
    driver = "org.postgresql.Driver"
    user = "postgres"
    password = "postgres"
    query = "INSERT INTO staging.transactions (transaction_id, customer_id, transaction_type, amount, timestamp, merchant_name, merchant_category, location_city, location_state, is_weekend, hour, is_online, is_fraud, ingestion_timestamp) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)"
    source_table_name = "transactions_clean"
  }
}
